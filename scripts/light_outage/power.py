import warnings
warnings.filterwarnings("ignore")

import os, json, requests
from datetime import datetime, timedelta
import cloudscraper
from bs4 import BeautifulSoup

URLS = [
    {
        "name": "Ðœ.ÐšÐ¾Ñ†ÑŽÐ±Ð¸Ð½ÑÑŒÐºÐ¾Ð³Ð¾ 11",
        "url": "https://chernigiv.energy-ua.info/grafik/ÐœÐ˜Ð¥ÐÐ™Ð›Ðž-ÐšÐžÐ¦Ð®Ð‘Ð˜ÐÐ¡Ð¬ÐšÐ•/Ðœ.ÐšÐ¾Ñ†ÑŽÐ±Ð¸Ð½ÑÑŒÐºÐ¾Ð³Ð¾/11"
    }
]

BOT_TOKEN = os.environ["TELEGRAM_TOKEN"]
CHAT_ID = os.environ["TELEGRAM_TO"]

CACHE_FILE = "sent.json"
WINDOW_MIN = 30
WINDOW_MAX = 25  # Ñ‰Ð¾Ð± Ð½Ðµ ÑÐ¿Ð°Ð¼Ð¸Ð»Ð¾ Ð¿Ñ€Ð¸ ÐºÐ¾Ð¶Ð½Ð¾Ð¼Ñƒ Ð·Ð°Ð¿ÑƒÑÐºÑƒ

def send(msg):
    requests.post(
        f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
        data={"chat_id": CHAT_ID, "text": msg}
    )

if os.path.exists(CACHE_FILE):
    sent = json.load(open(CACHE_FILE))
else:
    sent = []

now = datetime.now()
scraper = cloudscraper.create_scraper()

for item in URLS:
    r = scraper.get(item["url"], timeout=15)
    soup = BeautifulSoup(r.text, "html.parser")
    spans = soup.select("div.periods_items > span")

    for s in spans:
        b = s.find_all("b")
        if len(b) < 2:
            continue

        start = datetime.combine(now.date(), datetime.strptime(b[0].text, "%H:%M").time())
        end   = datetime.combine(now.date(), datetime.strptime(b[1].text, "%H:%M").time())

        for t, label, msg in [
            (start, "start", f"âš¡ Ð’Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ Ñ‡ÐµÑ€ÐµÐ· 30 Ñ…Ð² ({b[0].text}â€“{b[1].text})"),
            (end, "end", f"ðŸ’¡ Ð¡Ð²Ñ–Ñ‚Ð»Ð¾ Ð¿Ð¾Ð²ÐµÑ€Ð½ÐµÑ‚ÑŒÑÑ Ñ‡ÐµÑ€ÐµÐ· 30 Ñ…Ð² ({b[1].text})"),
        ]:
            delta = (t - now).total_seconds() / 60
            key = f"{item['name']}|{label}|{t.isoformat()}"

            if WINDOW_MAX <= delta <= WINDOW_MIN and key not in sent:
                send(f"{item['name']}\n{msg}")
                sent.append(key)

json.dump(sent, open(CACHE_FILE, "w"))